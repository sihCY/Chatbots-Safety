{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae3fd7b4ac7f4f1bbc4a4fd7ad7fbdf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad4ef83147a14c8b98de12b04b69c19e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25d0812a4d0c4233b14455c2c235af88",
              "IPY_MODEL_1766b0b03ae4408c9af65dab9b5180a4",
              "IPY_MODEL_1ae37cf3011e470f9c7fdad9dde1b4e8"
            ]
          }
        },
        "ad4ef83147a14c8b98de12b04b69c19e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25d0812a4d0c4233b14455c2c235af88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8359d064ca364e3f9d7e83c80137fbde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e573381f34a411fba58deaf6fea130d"
          }
        },
        "1766b0b03ae4408c9af65dab9b5180a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6202ca0f9ab945ddb4afa4d71d2a0155",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5be2ef75648347609926d8110e03c932"
          }
        },
        "1ae37cf3011e470f9c7fdad9dde1b4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c9e8303734ed43b98885e8e168d44587",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760/760 [00:00&lt;00:00, 18.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9127626086414c30872146aad758d003"
          }
        },
        "8359d064ca364e3f9d7e83c80137fbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e573381f34a411fba58deaf6fea130d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6202ca0f9ab945ddb4afa4d71d2a0155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5be2ef75648347609926d8110e03c932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9e8303734ed43b98885e8e168d44587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9127626086414c30872146aad758d003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b5b312c49fe496e9bb1b07d909022f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2922a2b88e0043a1b6dd5cd6f91ef9bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8428b59116ec44d68e197e1bdf49a632",
              "IPY_MODEL_a893509b31b94dd4a190d8a0177b558a",
              "IPY_MODEL_9c897b07a54246d8b44bf21d0790112c"
            ]
          }
        },
        "2922a2b88e0043a1b6dd5cd6f91ef9bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8428b59116ec44d68e197e1bdf49a632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8d647bfc1204e3680173e691578df20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecc0b2c58b5649a2a8c07dd3f5f8071f"
          }
        },
        "a893509b31b94dd4a190d8a0177b558a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_932fa7cb17634a7e914638ed3cb7a0ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467042463,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467042463,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0c9de2fe0f44d0788557a01cfa18e5b"
          }
        },
        "9c897b07a54246d8b44bf21d0790112c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b21d338a0b34c199c9a4f2ee04485f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:15&lt;00:00, 28.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_725d14e16c784583b27c3826e1f084fe"
          }
        },
        "c8d647bfc1204e3680173e691578df20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecc0b2c58b5649a2a8c07dd3f5f8071f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "932fa7cb17634a7e914638ed3cb7a0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0c9de2fe0f44d0788557a01cfa18e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b21d338a0b34c199c9a4f2ee04485f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "725d14e16c784583b27c3826e1f084fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnfdO13G18ig",
        "outputId": "33e46781-09a7-48df-f4fb-93822d95a6c5"
      },
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.20.23)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.23 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (1.23.23)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.23->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.23->boto3->pytorch-transformers) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.23->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-a2YmQC2aqb",
        "outputId": "201a3c15-9126-446d-c9f7-d1b76e30db6a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XS3rWnl23d9"
      },
      "source": [
        "directory_path='/content/drive/MyDrive/Sihem/XLNet_Classifier'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-dLb1A-3dOQ"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from pytorch_transformers import AdamW\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zkYKkE6PG-Gw",
        "outputId": "b548e8ce-124e-4c2c-f3fe-5718b9b58fc0"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FW0Xa5-Hjmj"
      },
      "source": [
        "df = pd.read_csv(directory_path+'/data.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "TR33I-aDHtuB",
        "outputId": "3840acba-7c8c-48f0-9592-125a442d4037"
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(84015, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You said you were leaving this site because I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Im weighing my heaviest ever at I remember sta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In general, testing for the human immunodefici...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fluids and electrolytes may be given by IV (in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In case of overdose, call your local poison co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0   You said you were leaving this site because I...      0\n",
              "1  Im weighing my heaviest ever at I remember sta...      0\n",
              "2  In general, testing for the human immunodefici...      1\n",
              "3  Fluids and electrolytes may be given by IV (in...      1\n",
              "4  In case of overdose, call your local poison co...      1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3iZeoQeMgL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b9a261-77a0-458d-b085-f53545bd52a3"
      },
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(83965, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMTv7luCW_be",
        "outputId": "ba3bd3b1-3481-432c-80fe-e1208e15ddfa"
      },
      "source": [
        "df=df[:67171]\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    34302\n",
              "0    32869\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nYG1yw6CH7GX",
        "outputId": "cc5ac54f-ffa4-4679-c358-8d106cd9a422"
      },
      "source": [
        "sentences = df.text.values\n",
        "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]\n",
        "labels = df.label.values\n",
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' You said you were leaving this site because I feel horrible awkward why I even came to reddit Don torture yourself like that  [SEP] [CLS]'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcmRzeNeIDfk",
        "outputId": "dee67db8-69cb-4c73-c1d8-17fb8f65a580"
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 798011/798011 [00:00<00:00, 867155.32B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfzIfMCGILaU",
        "outputId": "24a84131-456f-4e9a-d81a-7230039ddb53"
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the first sentence:\n",
            "['▁you', '▁said', '▁you', '▁were', '▁leaving', '▁this', '▁site', '▁because', '▁', 'i', '▁feel', '▁horrible', '▁awkward', '▁why', '▁', 'i', '▁even', '▁came', '▁to', '▁red', 'dit', '▁don', '▁torture', '▁yourself', '▁like', '▁that', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ktvodzIS1h"
      },
      "source": [
        "MAX_LEN = 128\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syAzwO6QIhae"
      },
      "source": [
        "#Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=56, test_size=0.2)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=56, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk3hz5z6IuWo"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGWnXYsyI7YK"
      },
      "source": [
        "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ae3fd7b4ac7f4f1bbc4a4fd7ad7fbdf8",
            "ad4ef83147a14c8b98de12b04b69c19e",
            "25d0812a4d0c4233b14455c2c235af88",
            "1766b0b03ae4408c9af65dab9b5180a4",
            "1ae37cf3011e470f9c7fdad9dde1b4e8",
            "8359d064ca364e3f9d7e83c80137fbde",
            "2e573381f34a411fba58deaf6fea130d",
            "6202ca0f9ab945ddb4afa4d71d2a0155",
            "5be2ef75648347609926d8110e03c932",
            "c9e8303734ed43b98885e8e168d44587",
            "9127626086414c30872146aad758d003",
            "6b5b312c49fe496e9bb1b07d909022f4",
            "2922a2b88e0043a1b6dd5cd6f91ef9bd",
            "8428b59116ec44d68e197e1bdf49a632",
            "a893509b31b94dd4a190d8a0177b558a",
            "9c897b07a54246d8b44bf21d0790112c",
            "c8d647bfc1204e3680173e691578df20",
            "ecc0b2c58b5649a2a8c07dd3f5f8071f",
            "932fa7cb17634a7e914638ed3cb7a0ce",
            "b0c9de2fe0f44d0788557a01cfa18e5b",
            "8b21d338a0b34c199c9a4f2ee04485f7",
            "725d14e16c784583b27c3826e1f084fe"
          ]
        },
        "id": "4bZ1gRBjOLff",
        "outputId": "f97470b1-85d6-4521-eea3-71079342cbaa"
      },
      "source": [
        "# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top.\n",
        "from transformers import XLNetForSequenceClassification\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae3fd7b4ac7f4f1bbc4a4fd7ad7fbdf8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b5b312c49fe496e9bb1b07d909022f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-FruYphOS1b"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejl-xhBeTVtU"
      },
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                     lr=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCh-trMWXuvo"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "9mGBwaM5HZgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zvFS_-ATtCT",
        "outputId": "084a8015-53dc-4f97-9489-3ee1bcdafbe7"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "\n",
        "  # Training\n",
        "\n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    loss = outputs[0]\n",
        "    logits = outputs[1]\n",
        "    train_loss_set.append(loss.item())\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      logits = output[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0015650395246482383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [52:18<1:44:36, 3138.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9994791666666667\n",
            "Train loss: 0.0010285414674285676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [1:44:39<52:20, 3140.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9998511904761904\n",
            "Train loss: 0.0013171536107436277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 3/3 [2:36:56<00:00, 3138.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9996279761904762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK2jdRTLZ4eG"
      },
      "source": [
        "torch.save(model.state_dict(), directory_path+'/XLNet_model.ckpt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(directory_path+'/data.csv')"
      ],
      "metadata": {
        "id": "rzx_L5zU8azr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tFspdvY8lRn",
        "outputId": "95378ea2-6ab0-47b6-d68c-63259aef06c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(83965, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[67171:]\n",
        "print(df.label.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTEzBj-C0kI-",
        "outputId": "70e1737f-85fa-4e0c-f741-1e999f91c1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    8541\n",
            "0    8253\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7J8KrkWQHgx"
      },
      "source": [
        "# Create sentence and label lists\n",
        "sentences = df.text.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for XLNet to work properly\n",
        "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]\n",
        "labels = df.label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEkci4wTQ5JC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de73c14a-0e52-4853-a7e3-2ade6d2d9950"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "# Tracking variables\n",
        "test_accuracy = 0\n",
        "nb_test_steps= 0\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "  test_accuracy += tmp_test_accuracy\n",
        "  nb_test_steps += 1\n",
        "\n",
        "  print(\"Test Accuracy: {}\".format(test_accuracy/nb_test_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 1.0\n",
            "Test Accuracy: 0.9997874149659864\n",
            "Test Accuracy: 0.9997888513513513\n",
            "Test Accuracy: 0.9997902684563759\n",
            "Test Accuracy: 0.9997916666666666\n",
            "Test Accuracy: 0.9997930463576159\n",
            "Test Accuracy: 0.9997944078947368\n",
            "Test Accuracy: 0.9997957516339869\n",
            "Test Accuracy: 0.999797077922078\n",
            "Test Accuracy: 0.9997983870967742\n",
            "Test Accuracy: 0.9997996794871795\n",
            "Test Accuracy: 0.9998009554140127\n",
            "Test Accuracy: 0.9998022151898734\n",
            "Test Accuracy: 0.9998034591194969\n",
            "Test Accuracy: 0.9998046875\n",
            "Test Accuracy: 0.999805900621118\n",
            "Test Accuracy: 0.9998070987654321\n",
            "Test Accuracy: 0.999808282208589\n",
            "Test Accuracy: 0.9998094512195121\n",
            "Test Accuracy: 0.999810606060606\n",
            "Test Accuracy: 0.9998117469879518\n",
            "Test Accuracy: 0.999812874251497\n",
            "Test Accuracy: 0.9998139880952381\n",
            "Test Accuracy: 0.9998150887573964\n",
            "Test Accuracy: 0.9998161764705882\n",
            "Test Accuracy: 0.9998172514619883\n",
            "Test Accuracy: 0.9998183139534884\n",
            "Test Accuracy: 0.9998193641618497\n",
            "Test Accuracy: 0.9998204022988506\n",
            "Test Accuracy: 0.9998214285714285\n",
            "Test Accuracy: 0.9998224431818182\n",
            "Test Accuracy: 0.9998234463276836\n",
            "Test Accuracy: 0.9998244382022472\n",
            "Test Accuracy: 0.9998254189944135\n",
            "Test Accuracy: 0.9998263888888889\n",
            "Test Accuracy: 0.9998273480662984\n",
            "Test Accuracy: 0.9998282967032966\n",
            "Test Accuracy: 0.9998292349726776\n",
            "Test Accuracy: 0.9998301630434783\n",
            "Test Accuracy: 0.9998310810810811\n",
            "Test Accuracy: 0.9998319892473119\n",
            "Test Accuracy: 0.9998328877005348\n",
            "Test Accuracy: 0.9998337765957447\n",
            "Test Accuracy: 0.999834656084656\n",
            "Test Accuracy: 0.9998355263157894\n",
            "Test Accuracy: 0.9998363874345549\n",
            "Test Accuracy: 0.9998372395833334\n",
            "Test Accuracy: 0.9998380829015544\n",
            "Test Accuracy: 0.9998389175257731\n",
            "Test Accuracy: 0.9998397435897436\n",
            "Test Accuracy: 0.9998405612244898\n",
            "Test Accuracy: 0.9998413705583756\n",
            "Test Accuracy: 0.9998421717171717\n",
            "Test Accuracy: 0.9998429648241206\n",
            "Test Accuracy: 0.99984375\n",
            "Test Accuracy: 0.9998445273631841\n",
            "Test Accuracy: 0.9998452970297029\n",
            "Test Accuracy: 0.9998460591133005\n",
            "Test Accuracy: 0.9998468137254902\n",
            "Test Accuracy: 0.9998475609756098\n",
            "Test Accuracy: 0.9998483009708737\n",
            "Test Accuracy: 0.9998490338164251\n",
            "Test Accuracy: 0.9998497596153846\n",
            "Test Accuracy: 0.9998504784688995\n",
            "Test Accuracy: 0.9998511904761904\n",
            "Test Accuracy: 0.9998518957345972\n",
            "Test Accuracy: 0.9998525943396226\n",
            "Test Accuracy: 0.9998532863849765\n",
            "Test Accuracy: 0.9998539719626168\n",
            "Test Accuracy: 0.9998546511627907\n",
            "Test Accuracy: 0.9998553240740741\n",
            "Test Accuracy: 0.9998559907834101\n",
            "Test Accuracy: 0.9998566513761468\n",
            "Test Accuracy: 0.999857305936073\n",
            "Test Accuracy: 0.9998579545454546\n",
            "Test Accuracy: 0.9998585972850679\n",
            "Test Accuracy: 0.9998592342342343\n",
            "Test Accuracy: 0.999859865470852\n",
            "Test Accuracy: 0.9998604910714286\n",
            "Test Accuracy: 0.9998611111111111\n",
            "Test Accuracy: 0.9998617256637168\n",
            "Test Accuracy: 0.9998623348017621\n",
            "Test Accuracy: 0.9998629385964912\n",
            "Test Accuracy: 0.9998635371179039\n",
            "Test Accuracy: 0.9998641304347826\n",
            "Test Accuracy: 0.9998647186147186\n",
            "Test Accuracy: 0.9998653017241379\n",
            "Test Accuracy: 0.9998658798283262\n",
            "Test Accuracy: 0.9998664529914529\n",
            "Test Accuracy: 0.9998670212765958\n",
            "Test Accuracy: 0.9998675847457628\n",
            "Test Accuracy: 0.9998681434599156\n",
            "Test Accuracy: 0.9998686974789915\n",
            "Test Accuracy: 0.9998692468619247\n",
            "Test Accuracy: 0.9998697916666667\n",
            "Test Accuracy: 0.9998703319502075\n",
            "Test Accuracy: 0.999870867768595\n",
            "Test Accuracy: 0.9998713991769548\n",
            "Test Accuracy: 0.9998719262295082\n",
            "Test Accuracy: 0.9998724489795918\n",
            "Test Accuracy: 0.9998729674796748\n",
            "Test Accuracy: 0.9998734817813765\n",
            "Test Accuracy: 0.9998739919354839\n",
            "Test Accuracy: 0.9998744979919679\n",
            "Test Accuracy: 0.99975\n",
            "Test Accuracy: 0.9997509960159362\n",
            "Test Accuracy: 0.9997519841269841\n",
            "Test Accuracy: 0.9997529644268774\n",
            "Test Accuracy: 0.999753937007874\n",
            "Test Accuracy: 0.9997549019607843\n",
            "Test Accuracy: 0.999755859375\n",
            "Test Accuracy: 0.9997568093385214\n",
            "Test Accuracy: 0.9997577519379846\n",
            "Test Accuracy: 0.9997586872586872\n",
            "Test Accuracy: 0.9997596153846153\n",
            "Test Accuracy: 0.9997605363984674\n",
            "Test Accuracy: 0.9997614503816794\n",
            "Test Accuracy: 0.9997623574144486\n",
            "Test Accuracy: 0.9997632575757576\n",
            "Test Accuracy: 0.9997641509433962\n",
            "Test Accuracy: 0.9997650375939849\n",
            "Test Accuracy: 0.9997659176029963\n",
            "Test Accuracy: 0.9997667910447762\n",
            "Test Accuracy: 0.9997676579925651\n",
            "Test Accuracy: 0.9997685185185186\n",
            "Test Accuracy: 0.9997693726937269\n",
            "Test Accuracy: 0.9997702205882353\n",
            "Test Accuracy: 0.9997710622710623\n",
            "Test Accuracy: 0.999771897810219\n",
            "Test Accuracy: 0.9997727272727273\n",
            "Test Accuracy: 0.9997735507246377\n",
            "Test Accuracy: 0.9997743682310469\n",
            "Test Accuracy: 0.9997751798561151\n",
            "Test Accuracy: 0.9997759856630825\n",
            "Test Accuracy: 0.9997767857142857\n",
            "Test Accuracy: 0.9997775800711743\n",
            "Test Accuracy: 0.9997783687943262\n",
            "Test Accuracy: 0.9997791519434629\n",
            "Test Accuracy: 0.9997799295774648\n",
            "Test Accuracy: 0.9997807017543859\n",
            "Test Accuracy: 0.9997814685314685\n",
            "Test Accuracy: 0.9997822299651568\n",
            "Test Accuracy: 0.9997829861111112\n",
            "Test Accuracy: 0.9997837370242214\n",
            "Test Accuracy: 0.9997844827586206\n",
            "Test Accuracy: 0.9997852233676976\n",
            "Test Accuracy: 0.9997859589041096\n",
            "Test Accuracy: 0.9997866894197952\n",
            "Test Accuracy: 0.9997874149659864\n",
            "Test Accuracy: 0.9997881355932203\n",
            "Test Accuracy: 0.9997888513513513\n",
            "Test Accuracy: 0.9997895622895623\n",
            "Test Accuracy: 0.9997902684563759\n",
            "Test Accuracy: 0.9997909698996655\n",
            "Test Accuracy: 0.9997916666666666\n",
            "Test Accuracy: 0.9997923588039868\n",
            "Test Accuracy: 0.9997930463576159\n",
            "Test Accuracy: 0.9997937293729373\n",
            "Test Accuracy: 0.9997944078947368\n",
            "Test Accuracy: 0.9997950819672131\n",
            "Test Accuracy: 0.9997957516339869\n",
            "Test Accuracy: 0.9997964169381107\n",
            "Test Accuracy: 0.999797077922078\n",
            "Test Accuracy: 0.9997977346278317\n",
            "Test Accuracy: 0.9997983870967742\n",
            "Test Accuracy: 0.9997990353697749\n",
            "Test Accuracy: 0.9997996794871795\n",
            "Test Accuracy: 0.9998003194888179\n",
            "Test Accuracy: 0.9998009554140127\n",
            "Test Accuracy: 0.9998015873015873\n",
            "Test Accuracy: 0.9998022151898734\n",
            "Test Accuracy: 0.9998028391167192\n",
            "Test Accuracy: 0.9998034591194969\n",
            "Test Accuracy: 0.9998040752351097\n",
            "Test Accuracy: 0.9998046875\n",
            "Test Accuracy: 0.9998052959501558\n",
            "Test Accuracy: 0.999805900621118\n",
            "Test Accuracy: 0.9998065015479877\n",
            "Test Accuracy: 0.9998070987654321\n",
            "Test Accuracy: 0.9998076923076923\n",
            "Test Accuracy: 0.999808282208589\n",
            "Test Accuracy: 0.9998088685015291\n",
            "Test Accuracy: 0.9998094512195121\n",
            "Test Accuracy: 0.9998100303951368\n",
            "Test Accuracy: 0.999810606060606\n",
            "Test Accuracy: 0.9998111782477341\n",
            "Test Accuracy: 0.9998117469879518\n",
            "Test Accuracy: 0.9998123123123123\n",
            "Test Accuracy: 0.999812874251497\n",
            "Test Accuracy: 0.9998134328358209\n",
            "Test Accuracy: 0.9998139880952381\n",
            "Test Accuracy: 0.9998145400593472\n",
            "Test Accuracy: 0.9998150887573964\n",
            "Test Accuracy: 0.9998156342182891\n",
            "Test Accuracy: 0.9998161764705882\n",
            "Test Accuracy: 0.9998167155425219\n",
            "Test Accuracy: 0.9998172514619883\n",
            "Test Accuracy: 0.9998177842565598\n",
            "Test Accuracy: 0.9998183139534884\n",
            "Test Accuracy: 0.9998188405797102\n",
            "Test Accuracy: 0.9998193641618497\n",
            "Test Accuracy: 0.9998198847262247\n",
            "Test Accuracy: 0.9998204022988506\n",
            "Test Accuracy: 0.9998209169054442\n",
            "Test Accuracy: 0.9998214285714285\n",
            "Test Accuracy: 0.9998219373219374\n",
            "Test Accuracy: 0.9998224431818182\n",
            "Test Accuracy: 0.9998229461756374\n",
            "Test Accuracy: 0.9998234463276836\n",
            "Test Accuracy: 0.9998239436619718\n",
            "Test Accuracy: 0.9998244382022472\n",
            "Test Accuracy: 0.9998249299719888\n",
            "Test Accuracy: 0.9998254189944135\n",
            "Test Accuracy: 0.9998259052924791\n",
            "Test Accuracy: 0.9998263888888889\n",
            "Test Accuracy: 0.9998268698060941\n",
            "Test Accuracy: 0.9998273480662984\n",
            "Test Accuracy: 0.9998278236914601\n",
            "Test Accuracy: 0.9998282967032966\n",
            "Test Accuracy: 0.9998287671232877\n",
            "Test Accuracy: 0.9998292349726776\n",
            "Test Accuracy: 0.9998297002724795\n",
            "Test Accuracy: 0.9998301630434783\n",
            "Test Accuracy: 0.9998306233062331\n",
            "Test Accuracy: 0.9998310810810811\n",
            "Test Accuracy: 0.9998315363881402\n",
            "Test Accuracy: 0.9998319892473119\n",
            "Test Accuracy: 0.9998324396782842\n",
            "Test Accuracy: 0.9998328877005348\n",
            "Test Accuracy: 0.99975\n",
            "Test Accuracy: 0.999750664893617\n",
            "Test Accuracy: 0.999751326259947\n",
            "Test Accuracy: 0.9997519841269841\n",
            "Test Accuracy: 0.9997526385224275\n",
            "Test Accuracy: 0.9997532894736842\n",
            "Test Accuracy: 0.999753937007874\n",
            "Test Accuracy: 0.9997545811518325\n",
            "Test Accuracy: 0.9997552219321149\n",
            "Test Accuracy: 0.999755859375\n",
            "Test Accuracy: 0.9997564935064935\n",
            "Test Accuracy: 0.9997571243523317\n",
            "Test Accuracy: 0.9997577519379846\n",
            "Test Accuracy: 0.9997583762886598\n",
            "Test Accuracy: 0.999758997429306\n",
            "Test Accuracy: 0.9997596153846153\n",
            "Test Accuracy: 0.9997602301790282\n",
            "Test Accuracy: 0.9997608418367347\n",
            "Test Accuracy: 0.9997614503816794\n",
            "Test Accuracy: 0.9997620558375635\n",
            "Test Accuracy: 0.9996835443037975\n",
            "Test Accuracy: 0.9996843434343434\n",
            "Test Accuracy: 0.9996851385390428\n",
            "Test Accuracy: 0.9996859296482412\n",
            "Test Accuracy: 0.99968671679198\n",
            "Test Accuracy: 0.9996875\n",
            "Test Accuracy: 0.9996882793017456\n",
            "Test Accuracy: 0.9996890547263682\n",
            "Test Accuracy: 0.9996898263027295\n",
            "Test Accuracy: 0.999690594059406\n",
            "Test Accuracy: 0.9996913580246913\n",
            "Test Accuracy: 0.999692118226601\n",
            "Test Accuracy: 0.9996928746928747\n",
            "Test Accuracy: 0.9996936274509803\n",
            "Test Accuracy: 0.9996943765281173\n",
            "Test Accuracy: 0.9996951219512196\n",
            "Test Accuracy: 0.9996958637469586\n",
            "Test Accuracy: 0.9996966019417476\n",
            "Test Accuracy: 0.9996973365617433\n",
            "Test Accuracy: 0.9996980676328503\n",
            "Test Accuracy: 0.9996987951807229\n",
            "Test Accuracy: 0.9996995192307693\n",
            "Test Accuracy: 0.9997002398081535\n",
            "Test Accuracy: 0.999700956937799\n",
            "Test Accuracy: 0.9997016706443914\n",
            "Test Accuracy: 0.999702380952381\n",
            "Test Accuracy: 0.9997030878859857\n",
            "Test Accuracy: 0.9997037914691943\n",
            "Test Accuracy: 0.9997044917257684\n",
            "Test Accuracy: 0.9997051886792453\n",
            "Test Accuracy: 0.9997058823529412\n",
            "Test Accuracy: 0.999706572769953\n",
            "Test Accuracy: 0.9997072599531616\n",
            "Test Accuracy: 0.9997079439252337\n",
            "Test Accuracy: 0.9997086247086248\n",
            "Test Accuracy: 0.9997093023255814\n",
            "Test Accuracy: 0.9997099767981439\n",
            "Test Accuracy: 0.9997106481481481\n",
            "Test Accuracy: 0.9997113163972287\n",
            "Test Accuracy: 0.9997119815668203\n",
            "Test Accuracy: 0.9997126436781609\n",
            "Test Accuracy: 0.9997133027522935\n",
            "Test Accuracy: 0.9997139588100686\n",
            "Test Accuracy: 0.9997146118721462\n",
            "Test Accuracy: 0.9997152619589977\n",
            "Test Accuracy: 0.9997159090909091\n",
            "Test Accuracy: 0.9997165532879818\n",
            "Test Accuracy: 0.9997171945701357\n",
            "Test Accuracy: 0.9997178329571106\n",
            "Test Accuracy: 0.9997184684684685\n",
            "Test Accuracy: 0.9997191011235955\n",
            "Test Accuracy: 0.9997197309417041\n",
            "Test Accuracy: 0.9997203579418344\n",
            "Test Accuracy: 0.9997209821428571\n",
            "Test Accuracy: 0.9997216035634744\n",
            "Test Accuracy: 0.9997222222222222\n",
            "Test Accuracy: 0.9997228381374723\n",
            "Test Accuracy: 0.9997234513274337\n",
            "Test Accuracy: 0.9997240618101545\n",
            "Test Accuracy: 0.9997246696035242\n",
            "Test Accuracy: 0.9997252747252747\n",
            "Test Accuracy: 0.9997258771929824\n",
            "Test Accuracy: 0.99972647702407\n",
            "Test Accuracy: 0.9997270742358079\n",
            "Test Accuracy: 0.9997276688453159\n",
            "Test Accuracy: 0.9997282608695652\n",
            "Test Accuracy: 0.9997288503253796\n",
            "Test Accuracy: 0.9997294372294372\n",
            "Test Accuracy: 0.9997300215982722\n",
            "Test Accuracy: 0.9997306034482759\n",
            "Test Accuracy: 0.999731182795699\n",
            "Test Accuracy: 0.9997317596566524\n",
            "Test Accuracy: 0.9997323340471093\n",
            "Test Accuracy: 0.999732905982906\n",
            "Test Accuracy: 0.9997334754797441\n",
            "Test Accuracy: 0.9997340425531915\n",
            "Test Accuracy: 0.9997346072186837\n",
            "Test Accuracy: 0.9997351694915254\n",
            "Test Accuracy: 0.9997357293868921\n",
            "Test Accuracy: 0.9997362869198312\n",
            "Test Accuracy: 0.9997368421052631\n",
            "Test Accuracy: 0.9997373949579832\n",
            "Test Accuracy: 0.9997379454926625\n",
            "Test Accuracy: 0.9997384937238494\n",
            "Test Accuracy: 0.9997390396659708\n",
            "Test Accuracy: 0.9997395833333333\n",
            "Test Accuracy: 0.9997401247401247\n",
            "Test Accuracy: 0.9996758298755186\n",
            "Test Accuracy: 0.9996765010351967\n",
            "Test Accuracy: 0.9996771694214877\n",
            "Test Accuracy: 0.9996778350515464\n",
            "Test Accuracy: 0.9996784979423868\n",
            "Test Accuracy: 0.9996791581108829\n",
            "Test Accuracy: 0.9996798155737705\n",
            "Test Accuracy: 0.9996804703476483\n",
            "Test Accuracy: 0.9996811224489796\n",
            "Test Accuracy: 0.9996817718940937\n",
            "Test Accuracy: 0.999682418699187\n",
            "Test Accuracy: 0.9996830628803245\n",
            "Test Accuracy: 0.9996837044534413\n",
            "Test Accuracy: 0.9996843434343434\n",
            "Test Accuracy: 0.9996849798387096\n",
            "Test Accuracy: 0.9996856136820925\n",
            "Test Accuracy: 0.9996862449799196\n",
            "Test Accuracy: 0.999686873747495\n",
            "Test Accuracy: 0.9996875\n",
            "Test Accuracy: 0.999688123752495\n",
            "Test Accuracy: 0.9996887450199203\n",
            "Test Accuracy: 0.9996893638170974\n",
            "Test Accuracy: 0.9996899801587301\n",
            "Test Accuracy: 0.999690594059406\n",
            "Test Accuracy: 0.9996912055335968\n",
            "Test Accuracy: 0.9996918145956607\n",
            "Test Accuracy: 0.9996924212598425\n",
            "Test Accuracy: 0.9996930255402751\n",
            "Test Accuracy: 0.9996936274509803\n",
            "Test Accuracy: 0.9996942270058709\n",
            "Test Accuracy: 0.99969482421875\n",
            "Test Accuracy: 0.9996954191033138\n",
            "Test Accuracy: 0.9996960116731517\n",
            "Test Accuracy: 0.9996966019417476\n",
            "Test Accuracy: 0.9996971899224806\n",
            "Test Accuracy: 0.9996977756286267\n",
            "Test Accuracy: 0.999698359073359\n",
            "Test Accuracy: 0.9996989402697495\n",
            "Test Accuracy: 0.9996995192307693\n",
            "Test Accuracy: 0.9997000959692899\n",
            "Test Accuracy: 0.9997006704980843\n",
            "Test Accuracy: 0.9997012428298279\n",
            "Test Accuracy: 0.9997018129770993\n",
            "Test Accuracy: 0.999702380952381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  matthews = matthews_corrcoef(true_labels[i],\n",
        "                 np.argmax(predictions[i], axis=1).flatten())\n",
        "  matthews_set.append(matthews)"
      ],
      "metadata": {
        "id": "y8NtcDun_fPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matthews_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz7BBuEL_l2c",
        "outputId": "a8fd5b6b-97ac-4119-88a8-37d0ff0064f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9229582069908973,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.938872452190116,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9393364366277243,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9379228369755696,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9315409787235999,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "metadata": {
        "id": "-BQXwXFt_55z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matthews_corrcoef(flat_true_labels, flat_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuZ-vNzWAAIT",
        "outputId": "cecd6dc5-27bd-4343-8e83-641e3e3c69b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9994045452767156"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import precision_recall_fscore_support, classification_report, roc_auc_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "#'preds, labels = np.array(predictions), np.array(true_labels)\n",
        "#standard round approach\n",
        "pred_flat = flat_predictions\n",
        "pr, rec, f, _ = precision_recall_fscore_support(flat_true_labels, pred_flat, average='weighted')\n",
        "\n",
        "print(\"precision\", pr)\n",
        "print(\"recall\", rec)\n",
        "print(\"fscore_weighted\", f)\n",
        " #adjust threshold approach\n",
        "preds_adj = np.array([[float(el1),float(el2)] for el1,el2 in preds])\n",
        "preds_adj = softmax(preds_adj, axis = 1)\n",
        "roc_auc = roc_auc_score(labels, preds_adj[:, 1])\n",
        "print(\"roc_auc\", roc_auc)\n",
        "\n",
        "all_metrcis = []\n",
        "for threshold in [0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1]:\n",
        "        metrcis = []\n",
        "        pred_labels = (preds_adj[:, 1] >= threshold).astype(int)\n",
        "        metrcis.append(threshold)\n",
        "        metrcis.append(round(f1_score(labels, pred_labels, average='weighted'),2))\n",
        "        metrcis.append(round(precision_score(labels, pred_labels),2))\n",
        "        metrcis.append(round(recall_score(labels, pred_labels),2))\n",
        "        metrcis.append(round(accuracy_score(labels, pred_labels),2))\n",
        "        all_metrcis.append(metrcis)\n",
        "\n",
        "df_metrics = pd.DataFrame(data = all_metrcis, columns = ['threshold','f1','prec','rec','acc'])\n",
        "df_metrics = df_metrics.sort_values(by='f1', ascending=False)\n",
        "\n",
        "print(classification_report(labels, pred_flat))\n",
        "\n",
        "print(df_metrics.head())\n",
        "\n",
        "cm = confusion_matrix(labels, pred_flat, labels=[1,0])\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "ax.set_title('Confusion Matrix')\n",
        "\n",
        "ax.set_xlabel('Predicted Labels')\n",
        "ax.set_ylabel('True Labels')\n",
        "\n",
        "ax.xaxis.set_ticklabels(['MEDICAL', 'NON_MEDICAL'])\n",
        "ax.yaxis.set_ticklabels(['MEDICAL', 'NON_MEDICAl'])"
      ],
      "metadata": {
        "id": "nhqPk7HFqFml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}